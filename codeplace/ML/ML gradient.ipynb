{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный алгоритм"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нахождение точки минимума"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0758987284245605\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def func(x):\n",
    "    return 0.5 * x + 0.2 * x ** 2 - 0.1 * x ** 3\n",
    "\n",
    "def df(x):\n",
    "    return 0.5 + 0.4 * x - 0.3 * x ** 2\n",
    "\n",
    "x = -4\n",
    "n = 0.01\n",
    "N = 200\n",
    "\n",
    "for i in range(N):\n",
    "    x -= n * df(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аппроксимация функции нахождением коэффициентов модели и нахождение среднего эмпирического риска по модели, входным и выходным данным самой функции и через градиентный алгоритм с производной функционала качества со сменой приближений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.98645739 -0.41780964  0.10273088  0.0317247 ]\n",
      "0.13061463936073706\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def func(x):\n",
    "    return 0.1 * x**2 - np.sin(x) + 5.\n",
    "\n",
    "def df(w, func_x, xx):\n",
    "    return 2*((xx @ w - func_x) * xx).mean(1)\n",
    "\n",
    "coord_x = np.arange(-5.0, 5.0, 0.1)\n",
    "coord_y = func(coord_x)\n",
    "\n",
    "eta = np.array([0.1, 0.01, 0.001, 0.0001])\n",
    "w = np.array([0., 0., 0., 0.])\n",
    "N = 200\n",
    "\n",
    "coord_x = np.power(coord_x.reshape(-1, 1), range(4))\n",
    "for i in range(N):\n",
    "    w -= eta * df(w, coord_y, coord_x)\n",
    "\n",
    "Q = np.square((coord_x @ w.T - coord_y)).mean()\n",
    "print(w)\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отличие от предыдущего решения лишь в том, что дополнительно высчитывается начальное значение функционала качества, а также берется на каждом шаге одно случайное измерение из обучающей выборки, по которому определяются коэффициенты модели и пересчитывается функционал качества. Также выход из цикла возможен при достижении маленького значения функционала качества или к тому же по достижении определенного порога точности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def func(x):\n",
    "    return 0.5 * x**2 - 0.1 * 1/np.exp(-x) + 0.5 * np.cos(2*x) - 2.\n",
    "\n",
    "loss = lambda ax, fx: (ax-fx)**2\n",
    "model_a = lambda xx, ww: xx @ ww\n",
    "\n",
    "def df(w, func_x, xx):\n",
    "    return 2*((xx @ w - func_x) * xx.T)\n",
    "\n",
    "coord_x = np.arange(-5.0, 5.0, 0.1)\n",
    "coord_y = func(coord_x)\n",
    "\n",
    "sz = len(coord_x)\n",
    "eta = np.array([0.01, 0.001, 0.0001, 0.01, 0.01])\n",
    "w = np.array([0., 0., 0., 0., 0.])\n",
    "N = 500 \n",
    "lm = 0.02\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "coord_x = np.column_stack([\n",
    "    coord_x**0,\n",
    "    coord_x,\n",
    "    coord_x**2,\n",
    "    np.cos(2*coord_x),\n",
    "    np.sin(2*coord_x)\n",
    "])\n",
    "\n",
    "Qe = loss(model_a(coord_x, w), coord_y).mean()\n",
    "\n",
    "tolerance = 1e-6\n",
    "prev_loss = Qe\n",
    "\n",
    "for i in range(N):\n",
    "    k = np.random.randint(0, sz)\n",
    "    loss_k = loss(model_a(coord_x[k], w), coord_y[k])\n",
    "    w -= eta * (df(w, coord_y[k], coord_x[k]))\n",
    "    Qe = lm * loss_k + (1-lm) * Qe\n",
    "\n",
    "    if abs(loss_k - prev_loss) < tolerance:\n",
    "        break\n",
    "    \n",
    "    prev_loss = loss_k\n",
    "\n",
    "Q = loss(model_a(coord_x, w), coord_y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отличие от предыдущего решения лишь в том, что добавляется определенный параметр batch_size, который определяет размер батча, из которого высчитываются средние значения потерь и производной по среднему эмпирическому риску"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def func(x):\n",
    "    return 0.5 * x + 0.2 * x ** 2 - 0.05 * x ** 3 + 0.2 * np.sin(4 * x) - 2.5\n",
    "\n",
    "loss = lambda ax, fx: ((ax-fx)**2)\n",
    "model_a = lambda xx, ww: xx @ ww\n",
    "\n",
    "def df(w, func_x, xx):\n",
    "    return 2*((xx @ w - func_x) * xx.T).mean(1)\n",
    "\n",
    "coord_x = np.arange(-4.0, 6.0, 0.1)\n",
    "coord_y = func(coord_x)\n",
    "\n",
    "sz = len(coord_x)\n",
    "eta = np.array([0.1, 0.01, 0.001, 0.0001])\n",
    "w = np.array([0., 0., 0., 0.])\n",
    "N = 500\n",
    "lm = 0.02\n",
    "batch_size = 50\n",
    "\n",
    "coord_x = np.power(coord_x.reshape(-1, 1), range(4))\n",
    "\n",
    "Qe = loss(model_a(coord_x, w), coord_y).mean()\n",
    "np.random.seed(0)\n",
    "\n",
    "tolerance = 1e-6\n",
    "prev_loss = Qe\n",
    "\n",
    "for i in range(N):\n",
    "    k = np.random.randint(0, sz-batch_size)\n",
    "    loss_k = (loss(model_a(coord_x[k:k+batch_size], w), coord_y[k:k+batch_size])).mean()\n",
    "    w -= eta * (df(w, coord_y[k:k+batch_size], coord_x[k:k+batch_size]))\n",
    "    Qe = lm * loss_k + (1-lm) * Qe\n",
    "\n",
    "    if abs(loss_k - prev_loss) < tolerance:\n",
    "        break\n",
    "    \n",
    "    prev_loss = loss_k\n",
    "\n",
    "Q = loss(model_a(coord_x, w), coord_y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Две следующие программы являются повторениями двух предыдущих решений, но только это не задачи аппроксимации функций, а бинарной классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def loss(w, x, y):\n",
    "    M = np.dot(w, x) * y\n",
    "    return np.log2(1 + np.exp(-M))\n",
    "\n",
    "def df(w, x, y):\n",
    "    M = np.dot(w, x) * y\n",
    "    return -(np.exp(-M) * x * y) / (1 + np.exp(-M))\n",
    "\n",
    "data_x = [(3.0, 4.9), (2.7, 3.9), (3.0, 5.5), (2.6, 4.0), (2.9, 4.3), (3.1, 5.1), (2.2, 4.5), (2.3, 3.3), (2.7, 5.1), (3.3, 5.7), (2.8, 5.1), (2.8, 4.9), (2.5, 4.5), (2.8, 4.7), (3.2, 4.7), (3.2, 5.7), (2.8, 6.1), (3.6, 6.1), (2.8, 4.8), (2.9, 4.5), (3.1, 4.9), (2.3, 4.4), (3.3, 6.0), (2.6, 5.6), (3.0, 4.4), (2.9, 4.7), (2.8, 4.0), (2.5, 5.8), (2.4, 3.3), (2.8, 6.7), (3.0, 5.1), (2.3, 4.0), (3.1, 5.5), (2.8, 4.8), (2.7, 5.1), (2.5, 4.0), (3.1, 4.4), (3.8, 6.7), (3.1, 5.6), (3.1, 4.7), (3.0, 5.8), (3.0, 5.2), (3.0, 4.5), (2.7, 4.9), (3.0, 6.6), (2.9, 4.6), (3.0, 4.6), (2.6, 3.5), (2.7, 5.1), (2.5, 5.0), (2.0, 3.5), (3.2, 5.9), (2.5, 5.0), (3.4, 5.6), (3.4, 4.5), (3.2, 5.3), (2.2, 4.0), (2.2, 5.0), (3.3, 4.7), (2.7, 4.1), (2.4, 3.7), (3.0, 4.2), (3.2, 6.0), (3.0, 4.2), (3.0, 4.5), (2.7, 4.2), (2.5, 3.0), (2.8, 4.6), (2.9, 4.2), (3.1, 5.4), (2.5, 4.9), (3.2, 5.1), (2.8, 4.5), (2.8, 5.6), (3.4, 5.4), (2.7, 3.9), (3.0, 6.1), (3.0, 5.8), (3.0, 4.1), (2.5, 3.9), (2.4, 3.8), (2.6, 4.4), (2.9, 3.6), (3.3, 5.7), (2.9, 5.6), (3.0, 5.2), (3.0, 4.8), (2.7, 5.3), (2.8, 4.1), (2.8, 5.6), (3.2, 4.5), (3.0, 5.9), (2.9, 4.3), (2.6, 6.9), (2.8, 5.1), (2.9, 6.3), (3.2, 4.8), (3.0, 5.5), (3.0, 5.0), (3.8, 6.4)]\n",
    "data_y = [1, -1, 1, -1, -1, 1, -1, -1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, -1, -1, -1, 1, 1, -1, -1, -1, 1, -1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, -1, 1, 1, 1, -1, 1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, 1, 1, -1, 1, 1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, -1, 1, -1, 1, -1, 1, 1, 1, -1, 1, -1, 1]\n",
    "\n",
    "x_train = np.array([[1, x[0], x[1]] for x in data_x])\n",
    "y_train = np.array(data_y)\n",
    "\n",
    "n_train = len(x_train)\n",
    "w = [0.0, 0.0, 0.0]\n",
    "nt = np.array([0.5, 0.01, 0.01])\n",
    "lm = 0.01\n",
    "N = 1000\n",
    "\n",
    "Qe = 0\n",
    "np.random.seed(0)\n",
    "\n",
    "for i in range(N):\n",
    "    k = np.random.randint(0, n_train-1)\n",
    "    Qe = lm * loss(w, x_train[k], y_train[k]) + (1-lm) * Qe\n",
    "    w -= nt * df(w, x_train[k], y_train[k])\n",
    "\n",
    "Q = (x_train @ w * y_train < 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def loss(w, x, y):\n",
    "    M = np.dot(x, w) * y\n",
    "    return np.exp(-M).mean()\n",
    "\n",
    "def df(w, x, y, size):\n",
    "    M = np.dot(x, w) * y\n",
    "    return -np.dot(x.T, np.exp(-M) * y) / size\n",
    "\n",
    "data_x = [(5.8, 1.2), (5.6, 1.5), (6.5, 1.5), (6.1, 1.3), (6.4, 1.3), (7.7, 2.0), (6.0, 1.8), (5.6, 1.3), (6.0, 1.6), (5.8, 1.9), (5.7, 2.0), (6.3, 1.5), (6.2, 1.8), (7.7, 2.3), (5.8, 1.2), (6.3, 1.8), (6.0, 1.0), (6.2, 1.3), (5.7, 1.3), (6.3, 1.9), (6.7, 2.5), (5.5, 1.2), (4.9, 1.0), (6.1, 1.4), (6.0, 1.6), (7.2, 2.5), (7.3, 1.8), (6.6, 1.4), (5.6, 2.0), (5.5, 1.0), (6.4, 2.2), (5.6, 1.3), (6.6, 1.3), (6.9, 2.1), (6.8, 2.1), (5.7, 1.3), (7.0, 1.4), (6.1, 1.4), (6.1, 1.8), (6.7, 1.7), (6.0, 1.5), (6.5, 1.8), (6.4, 1.5), (6.9, 1.5), (5.6, 1.3), (6.7, 1.4), (5.8, 1.9), (6.3, 1.3), (6.7, 2.1), (6.2, 2.3), (6.3, 2.4), (6.7, 1.8), (6.4, 2.3), (6.2, 1.5), (6.1, 1.4), (7.1, 2.1), (5.7, 1.0), (6.8, 1.4), (6.8, 2.3), (5.1, 1.1), (4.9, 1.7), (5.9, 1.8), (7.4, 1.9), (6.5, 2.0), (6.7, 1.5), (6.5, 2.0), (5.8, 1.0), (6.4, 2.1), (7.6, 2.1), (5.8, 2.4), (7.7, 2.2), (6.3, 1.5), (5.0, 1.0), (6.3, 1.6), (7.7, 2.3), (6.4, 1.9), (6.5, 2.2), (5.7, 1.2), (6.9, 2.3), (5.7, 1.3), (6.1, 1.2), (5.4, 1.5), (5.2, 1.4), (6.7, 2.3), (7.9, 2.0), (5.6, 1.1), (7.2, 1.8), (5.5, 1.3), (7.2, 1.6), (6.3, 2.5), (6.3, 1.8), (6.7, 2.4), (5.0, 1.0), (6.4, 1.8), (6.9, 2.3), (5.5, 1.3), (5.5, 1.1), (5.9, 1.5), (6.0, 1.5), (5.9, 1.8)]\n",
    "data_y = [-1, -1, -1, -1, -1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, 1, -1, -1, -1, 1, 1, -1, -1, -1, -1, 1, 1, -1, 1, -1, 1, -1, -1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, -1, -1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, -1, -1, 1, -1, 1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, -1, -1, -1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, -1, 1]\n",
    "\n",
    "x_train = np.array([[1, x[0], x[1]] for x in data_x])\n",
    "y_train = np.array(data_y)\n",
    "\n",
    "n_train = len(x_train)\n",
    "w = np.array([0.0, 0.0, 0.0])\n",
    "nt = np.array([0.5, 0.01, 0.01])\n",
    "lm = 0.01\n",
    "N = 500\n",
    "batch_size = 10\n",
    "\n",
    "Qe = 0\n",
    "np.random.seed(0)\n",
    "\n",
    "tolerance = 1e-6\n",
    "prev_loss = Qe\n",
    "\n",
    "for i in range(N):\n",
    "    k = np.random.randint(0, n_train-batch_size-1)\n",
    "    batch_x = x_train[k:k+batch_size]\n",
    "    batch_y = y_train[k:k+batch_size]\n",
    "    loss_k = loss(w, batch_x, batch_y)\n",
    "    w -= nt * df(w, batch_x, batch_y, batch_size)\n",
    "    Qe = lm * loss_k + (1-lm) * Qe\n",
    "\n",
    "    if abs(loss_k - prev_loss) < tolerance:\n",
    "        break\n",
    "\n",
    "    prev_loss = loss_k\n",
    "\n",
    "Q = (np.dot(x_train, w) * y_train < 0).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
